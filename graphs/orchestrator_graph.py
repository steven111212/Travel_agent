import sys
import os
import json
import re
import litellm
from langchain_core.messages import HumanMessage, AIMessage
from typing import Annotated, TypedDict, List, Dict, Any, Optional
from langgraph.graph import StateGraph, END

# å¼•å…¥æ‚¨å·²ç¶“å‰µå»ºçš„å·¥å…·
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from tools import HighwayTool, ParkingTool, RouteTool, WeatherTool, GeneralTool
from config import LLM_BASE_URL, API_TYPE, MODEL, LLM_API_KEY

# å®šç¾©å­—å…¸éƒ¨åˆ†æ›´æ–°ç­–ç•¥
def assign_partial(current_dict, new_dict):
    """åˆä½µå…©å€‹å­—å…¸"""
    result = current_dict.copy()  # è¤‡è£½ç•¶å‰å­—å…¸
    result.update(new_dict)  # æ›´æ–°æ–°çš„å€¼
    return result

# åˆå§‹åŒ–å·¥å…·
highway_tool = HighwayTool()
route_tool = RouteTool()
weather_tool = WeatherTool()
parking_tool = ParkingTool()
general_tool = GeneralTool()


# å®šç¾©ç‹€æ…‹é¡å‹
class AgentState(TypedDict):
    """Agent ç‹€æ…‹å®šç¾©"""
    messages: List[Dict[str, str]]  # å°è©±æ­·å²
    query: str  # ç”¨æˆ¶æŸ¥è©¢
    tools_to_use: List[str]  # éœ€è¦ä½¿ç”¨çš„å·¥å…·
    tool_results: Annotated[Dict[str, str], assign_partial]
    final_response: Optional[str]

# å·¥å…·èª¿ç”¨å‡½æ•¸ä¹Ÿéœ€è¦ç°¡åŒ–
def call_highway_tool(state: AgentState) -> Dict[str, Any]:
    """èª¿ç”¨é«˜é€Ÿå…¬è·¯å·¥å…·"""
    print(f"èª¿ç”¨é«˜é€Ÿå…¬è·¯å·¥å…·ï¼ŒæŸ¥è©¢ï¼š{state['query']}")
    result = highway_tool._run(state["query"])
    # åªè¿”å›è¦æ›´æ–°çš„éµ
    return {"tool_results": {"highway": result}}

def call_route_tool(state: AgentState) -> Dict[str, Any]:
    """èª¿ç”¨è·¯ç·šè¦åŠƒå·¥å…·"""
    print(f"èª¿ç”¨è·¯ç·šè¦åŠƒå·¥å…·ï¼ŒæŸ¥è©¢ï¼š{state['query']}")
    result = route_tool._run(state["query"])
    return {"tool_results": {"route": result}}

def call_weather_tool(state: AgentState) -> Dict[str, Any]:
    """èª¿ç”¨å¤©æ°£å·¥å…·"""
    print(f"èª¿ç”¨å¤©æ°£å·¥å…·ï¼ŒæŸ¥è©¢ï¼š{state['query']}")
    result = weather_tool._run(state["query"])
    return {"tool_results": {"weather": result}}

def call_parking_tool(state: AgentState) -> Dict[str, Any]:
    """èª¿ç”¨åœè»Šå ´æŸ¥è©¢å·¥å…·"""
    print(f"èª¿ç”¨åœè»Šå ´æŸ¥è©¢å·¥å…·ï¼ŒæŸ¥è©¢ï¼š{state['query']}")
    result = parking_tool._run(state["query"])
    # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦æ·»åŠ åœè»Šå ´å·¥å…·çš„é‚è¼¯
    return {"tool_results": {"parking": result}}  # å‡è¨­è¿”å›çš„çµæœ

def call_general_tool(state: AgentState) -> Dict[str, Any]:
    """èª¿ç”¨ä¸€èˆ¬æ€§æ—…éŠæŸ¥è©¢å·¥å…·"""
    print(f"èª¿ç”¨ä¸€èˆ¬æ€§æ—…éŠæŸ¥è©¢å·¥å…·ï¼ŒæŸ¥è©¢ï¼š{state['query']}")
    result = general_tool._run(state["query"])
    return {"tool_results": {"general": result}}  # å‡è¨­è¿”å›çš„çµæœ

# æ±ºç­–å‡½æ•¸
def decide_tools(state: AgentState) -> Dict[str, Any]:
    """åˆ†ææŸ¥è©¢ï¼Œæ±ºå®šä½¿ç”¨å“ªäº›å·¥å…·"""
    query = state["query"]
    tools = analyze_query(query)
    print(f"æ±ºå®šä½¿ç”¨çš„å·¥å…·ï¼š{tools}")
    return {"tools_to_use": tools}

def analyze_query(query: str) -> List[str]:
    """
    åˆ†æç”¨æˆ¶æŸ¥è©¢ï¼Œæ±ºå®šæ‡‰è©²ä½¿ç”¨å“ªäº›å·¥å…·
    
    åƒæ•¸:
        query (str): ç”¨æˆ¶æŸ¥è©¢
        
    è¿”å›:
        List[str]: éœ€è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
    """
    # ä½¿ç”¨ LLM ä¾†åˆ¤æ–·éœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·
    prompt = create_analysis_prompt(query)
    messages = [{"role": "system", "content": prompt}]
    
    try:
        response = litellm.completion(
            api_key=LLM_API_KEY,
            api_base=LLM_BASE_URL,
            model=f"{API_TYPE}/{MODEL}",
            messages=messages,
            temperature=0.2
        )
        response_text = response.choices[0].message.content
        
        # è§£æ LLM å›æ‡‰
        tools_to_use = parse_llm_analysis(response_text)
        
        # å¦‚æœæ²’æœ‰è­˜åˆ¥å‡ºå·¥å…·ï¼Œé»˜èªä½¿ç”¨ä¸€èˆ¬æ€§æ—…éŠæŸ¥è©¢å·¥å…·
        if not tools_to_use:
            return ["general_tool"]
            
        return tools_to_use
        
    except Exception as e:
        print(f"å·¥å…·åˆ†ææ™‚å‡ºéŒ¯: {str(e)}")
        # å¦‚æœåˆ†æå¤±æ•—ï¼Œå˜—è©¦åŸºæ–¼é—œéµè©çš„ç°¡å–®è¦å‰‡ä¾†åˆ¤æ–·
        return fallback_tool_selection(query)

def create_analysis_prompt(query: str) -> str:
    """
    å‰µå»ºç”¨æ–¼åˆ†ææŸ¥è©¢çš„ LLM æç¤º
    
    åƒæ•¸:
        query (str): ç”¨æˆ¶æŸ¥è©¢
        
    è¿”å›:
        str: LLM æç¤º
    """
    prompt = f"""æ‚¨æ˜¯ä¸€å€‹å°ç£æ—…éŠåŠ©æ‰‹çš„æ„åœ–åˆ†æå™¨ã€‚è«‹åˆ†æç”¨æˆ¶çš„æŸ¥è©¢ä¸¦ç¢ºå®šéœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·ä¾†å›ç­”ã€‚

å¯ç”¨çš„å·¥å…·æœ‰:

1. highway_tool: æä¾›é«˜é€Ÿå…¬è·¯äº¤é€šç‹€æ³è³‡è¨Šï¼Œé©ç”¨æ–¼:
   - ç”¨æˆ¶è©¢å•ç‰¹å®šé«˜é€Ÿå…¬è·¯è·¯æ®µçš„å£…å¡æƒ…æ³
   - ç”¨æˆ¶è©¢å•å¾ä¸€åœ°åˆ°å¦ä¸€åœ°çš„é«˜é€Ÿå…¬è·¯ç‹€æ³
   - åŒ…å«é—œéµè©: åœ‹é“ã€é«˜é€Ÿå…¬è·¯ã€äº¤æµé“ã€å¡è»Šã€å£…å¡ã€è·¯æ³

2. route_tool: æä¾›è·¯ç·šè¦åŠƒï¼Œé©ç”¨æ–¼:
   - ç”¨æˆ¶è©¢å•å¾ä¸€åœ°åˆ°å¦ä¸€åœ°çš„è·¯ç·š
   - ç”¨æˆ¶è©¢å•å¤šæ™¯é»çš„è¡Œç¨‹è¦åŠƒ
   - åŒ…å«é—œéµè©: æ€éº¼å»ã€è·¯ç·šã€è·¯å¾‘ã€è¦åŠƒ

3. weather_tool: æä¾›å¤©æ°£è³‡è¨Šï¼Œé©ç”¨æ–¼:
   - ç”¨æˆ¶è©¢å•ç‰¹å®šåœ°é»çš„å¤©æ°£ç‹€æ³
   - ç”¨æˆ¶è©¢å•å¤šæ—¥çš„å¤©æ°£é å ±
   - å¿…é ˆåŒ…å«é—œéµè©: å¤©æ°£ã€æ°£æº«ã€é™é›¨ã€ä¸‹é›¨ã€æ¿•åº¦ã€ç´«å¤–ç·š
   - ç”¨æˆ¶æ²’æåˆ°å¤©æ°£çš„æƒ…æ³ä¸‹ï¼Œé€™å€‹å·¥å…·ä¸æœƒè¢«ä½¿ç”¨

4. parking_tool: æä¾›åœè»Šå ´è³‡è¨Šï¼Œé©ç”¨æ–¼:
   - ç”¨æˆ¶è©¢å•ç‰¹å®šåœ°é»çš„åœè»Šå ´è³‡è¨Š

è«‹åˆ†æä»¥ä¸‹ç”¨æˆ¶æŸ¥è©¢ï¼Œåˆ¤æ–·éœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·ä¾†å›ç­”ã€‚å¤šå€‹å·¥å…·å¯èƒ½éœ€è¦åŒæ™‚ä½¿ç”¨ã€‚

ç”¨æˆ¶æŸ¥è©¢: {query}

è«‹ä»¥ JSON æ ¼å¼å›è¦†ï¼Œåƒ…åŒ…å«å·¥å…·åç¨±åˆ—è¡¨:
{{
  "tools": ["tool_name1", "tool_name2", ...]
}}
åªéœ€è¿”å› JSONï¼Œä¸éœ€è¦ä»»ä½•å…¶ä»–è§£é‡‹ã€‚"""
    
    return prompt

def parse_llm_analysis(response_text: str) -> List[str]:
    """
    è§£æ LLM å›æ‡‰ï¼Œæå–éœ€è¦ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
    
    åƒæ•¸:
        response_text (str): LLM å›æ‡‰æ–‡æœ¬
        
    è¿”å›:
        List[str]: å·¥å…·åˆ—è¡¨
    """
    try:
        # å˜—è©¦åŒ¹é… JSON å…§å®¹
        json_pattern = r'```json\s*({.*?})\s*```|^{.*}$'
        match = re.search(json_pattern, response_text, re.DOTALL)
        
        if match:
            json_str = match.group(1) if match.group(1) else match.group(0)
            json_str = json_str.strip()
            result = json.loads(json_str)
            return result.get("tools", [])
        
        # å¦‚æœæ²’æœ‰åŒ¹é…åˆ° JSONï¼Œå˜—è©¦ç›´æ¥è§£æå·¥å…·åç¨±
        tool_pattern = r'(highway_tool|route_tool|weather_tool|parking_tool)'
        matches = re.findall(tool_pattern, response_text)
        return list(set(matches))
        
    except Exception as e:
        print(f"è§£æå·¥å…·åˆ†æçµæœæ™‚å‡ºéŒ¯: {str(e)}")
        return []

def fallback_tool_selection(query: str) -> List[str]:
    """
    åŸºæ–¼é—œéµè©çš„ç°¡å–®è¦å‰‡ä¾†é¸æ“‡å·¥å…· (ä½œç‚ºåˆ†æå¤±æ•—æ™‚çš„å‚™é¸æ–¹æ¡ˆ)
    
    åƒæ•¸:
        query (str): ç”¨æˆ¶æŸ¥è©¢
        
    è¿”å›:
        List[str]: å·¥å…·åˆ—è¡¨
    """
    tools = []
    
    # é«˜é€Ÿå…¬è·¯ç›¸é—œé—œéµè©
    highway_keywords = ["åœ‹é“", "é«˜é€Ÿå…¬è·¯", "äº¤æµé“", "å¡è»Š", "å£…å¡", "è·¯æ³", 
                       "ä¸­å±±é«˜", "äºŒé«˜", "åœ‹1", "åœ‹3", "åœ‹5"]
    
    # è·¯ç·šè¦åŠƒç›¸é—œé—œéµè©
    route_keywords = ["æ€éº¼å»", "è·¯ç·š", "è·¯å¾‘", "è¦åŠƒ", "å¾", "åˆ°", "å‰å¾€", 
                     "å‡ºç™¼", "æŠµé”", "è·é›¢", "æ™‚é–“"]
    
    # å¤©æ°£ç›¸é—œé—œéµè©
    weather_keywords = ["å¤©æ°£", "æ°£æº«", "é™é›¨", "æ¿•åº¦", "ç´«å¤–ç·š", "ä¸‹é›¨", 
                       "æ™´å¤©", "é™°å¤©", "é¢±é¢¨", "æº«åº¦"]
    
    # åœè»Šå ´ç›¸é—œé—œéµè©
    parking_keywords = ["åœè»Šå ´", "åœè»Šä½", "åœè»Š", "åœè»Šè³‡è¨Š",]
    
    # æª¢æŸ¥æŸ¥è©¢ä¸­æ˜¯å¦åŒ…å«å„é¡é—œéµè©
    query_lower = query.lower()
    
    if any(keyword in query_lower for keyword in highway_keywords):
        tools.append("highway_tool")
        
    if any(keyword in query_lower for keyword in route_keywords):
        tools.append("route_tool")
        
    if any(keyword in query_lower for keyword in weather_keywords):
        tools.append("weather_tool")

    if any(keyword in query_lower for keyword in parking_keywords):
        tools.append("parking_tool")
    
    # å¦‚æœæ²’æœ‰åŒ¹é…ä»»ä½•å·¥å…·ï¼Œè¿”å›æ‰€æœ‰å·¥å…·
    if not tools:
        return ["general_tool"]
        
    return tools

# é¸æ“‡ä¸‹ä¸€æ­¥
def route_to_tools(state: AgentState) -> List[str]:
    """
    æ ¹æ“šæ±ºç­–çµæœé¸æ“‡ä¸‹ä¸€æ­¥èª¿ç”¨å“ªäº›å·¥å…·
    
    åƒæ•¸:
        state (AgentState): ç•¶å‰ç‹€æ…‹
        
    è¿”å›:
        List[str]: éœ€è¦åŸ·è¡Œçš„ç¯€é»åˆ—è¡¨
    """
    tools = state["tools_to_use"]
    result = []

    # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šå·¥å…·
    specific_tools = False
    
    if "highway_tool" in tools:
        result.append("highway")
        specific_tools = True
    if "route_tool" in tools:
        result.append("route")
        specific_tools = True
    if "weather_tool" in tools:
        result.append("weather")
        specific_tools = True
    if "parking_tool" in tools:
        result.append("parking")
        specific_tools = True
    # åªæœ‰åœ¨æ²’æœ‰å…¶ä»–ç‰¹å®šå·¥å…·æ™‚ï¼Œæ‰ä½¿ç”¨ general_tool
    if not specific_tools and "general_tool" in tools:
        result.append("general")
    
    # é—œéµï¼šè¿”å›ä¸€å€‹ç¯€é»åˆ—è¡¨ï¼Œé€™äº›ç¯€é»æœƒè¢«ä¸¦è¡ŒåŸ·è¡Œ
    if result:
        return result
    
    # å¦‚æœæ²’æœ‰å·¥å…·éœ€è¦èª¿ç”¨ï¼Œç›´æ¥é€²å…¥åˆæˆéšæ®µ
    return ["synthesize"]

# åˆæˆçµæœ
def synthesize_results(state: AgentState) -> Dict[str, Any]:
    """
    æ•´åˆæ‰€æœ‰å·¥å…·çš„çµæœ
    
    åƒæ•¸:
        state (AgentState): ç•¶å‰ç‹€æ…‹
        
    è¿”å›:
        Dict[str, Any]: æ›´æ–°å¾Œçš„ç‹€æ…‹
    """
    query = state["query"]
    tool_results = state["tool_results"]
    
    # ç•¶æ²’æœ‰å·¥å…·çµæœæ™‚çš„è™•ç†
    if not tool_results:
        response = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†æ‚¨çš„æŸ¥è©¢ã€‚è«‹å˜—è©¦æä¾›æ›´å…·é«”çš„å•é¡Œã€‚"
        return {
            "final_response": response,
            "messages": state["messages"] + [{"role": "assistant", "content": response}]
        }
    
    # ä½¿ç”¨ LLM æ•´åˆå¤šå€‹å·¥å…·çš„å›æ‡‰
    integrated_response = integrate_responses(query, tool_results)
    
    # æ›´æ–°ç‹€æ…‹
    return {
        "final_response": integrated_response,
        "messages": state["messages"] + [{"role": "assistant", "content": integrated_response}]
    }

def integrate_responses(query: str, tool_responses: Dict[str, str]) -> str:
    """
    æ•´åˆå„å·¥å…·çš„å›æ‡‰ï¼Œç”Ÿæˆæœ€çµ‚çš„å›æ‡‰
    å„ªåŒ–ç‰ˆæœ¬ï¼šç›´æ¥æ‹¼æ¥å¤šå€‹å·¥å…·çš„çµæœï¼Œä¸ä½¿ç”¨ LLM æ•´åˆ
    
    åƒæ•¸:
        query (str): åŸå§‹ç”¨æˆ¶æŸ¥è©¢
        tool_responses (Dict[str, str]): å„å·¥å…·çš„å›æ‡‰
        
    è¿”å›:
        str: æ•´åˆå¾Œçš„å›æ‡‰
    """
    # å¦‚æœåªæœ‰ä¸€å€‹å·¥å…·çš„å›æ‡‰ï¼Œç›´æ¥è¿”å›
    if len(tool_responses) == 1:
        return list(tool_responses.values())[0]
    
    # å¤šå€‹å·¥å…·å›æ‡‰æ™‚ï¼Œç›´æ¥æ‹¼æ¥è€Œä¸ä½¿ç”¨ LLM
    result = "ä»¥ä¸‹æ˜¯æ‚¨æŸ¥è©¢çš„ç›¸é—œè³‡è¨Š:\n\n"
    
    # æ ¹æ“šå·¥å…·çš„é¡å‹å„ªå…ˆæ’åº
    if "route" in tool_responses and "highway" not in tool_responses:
        result += "ğŸ—ºï¸ è·¯ç·šè¦åŠƒ:\n"
        result += tool_responses["route"] + "\n\n"
        
    if "weather" in tool_responses:
        result += "ğŸŒ¤ï¸ å¤©æ°£è³‡è¨Š:\n"
        result += tool_responses["weather"] + "\n\n"

    if "highway" in tool_responses:
        result += "ğŸ›£ï¸ é«˜é€Ÿå…¬è·¯äº¤é€šè³‡è¨Š:\n"
        result += tool_responses["highway"] + "\n\n"

    if "parking" in tool_responses:
        result += "ğŸ…¿ï¸ åœè»Šå ´è³‡è¨Š:\n"
        result += tool_responses["parking"] + "\n\n"
    
    if "general" in tool_responses:
        result += "ğŸ’¬ ä¸€èˆ¬æ—…éŠå»ºè­°:\n"
        result += tool_responses["general"] + "\n\n"
    
    # ç°¡å–®çš„ç¸½çµ
    if len(tool_responses) >= 2:
        result += "å¸Œæœ›ä»¥ä¸Šè³‡è¨Šèƒ½å¹«åŠ©åˆ°æ‚¨ï¼ç¥æ‚¨æ—…é€”æ„‰å¿«ã€‚\n"
        
    return result

def create_integration_prompt(query: str, tool_responses: Dict[str, str]) -> str:
    """
    å‰µå»ºç”¨æ–¼æ•´åˆå›æ‡‰çš„ LLM æç¤º
    
    åƒæ•¸:
        query (str): ç”¨æˆ¶æŸ¥è©¢
        tool_responses (Dict[str, str]): å„å·¥å…·çš„å›æ‡‰
        
    è¿”å›:
        str: LLM æç¤º
    """
    # æ§‹å»ºæç¤ºå…§å®¹
    prompt = f"""æ‚¨æ˜¯ä¸€å€‹å°ç£æ—…éŠåŠ©æ‰‹ï¼Œè² è²¬å°‡å¤šå€‹å°ˆæ¥­å·¥å…·çš„å›æ‡‰æ•´åˆæˆä¸€å€‹é€£è²«ã€å‹å–„ã€æœ‰çµ„ç¹”çš„å›æ‡‰ã€‚

ç”¨æˆ¶åŸå§‹æŸ¥è©¢:
{query}

ä»¥ä¸‹æ˜¯å„å€‹å°ˆæ¥­å·¥å…·çš„å›æ‡‰:
"""
    if "highway" in tool_responses:
        prompt += f"""
==== é«˜é€Ÿå…¬è·¯äº¤é€šè³‡è¨Š ====
{tool_responses["highway"]}
"""
    
    if "route" in tool_responses:
        prompt += f"""
==== è·¯ç·šè¦åŠƒ ====
{tool_responses["route"]}
"""
    
    if "weather" in tool_responses:
        prompt += f"""
==== å¤©æ°£è³‡è¨Š ====
{tool_responses["weather"]}
"""
    
    if "parking" in tool_responses:
        prompt += f"""
==== åœè»Šå ´è³‡è¨Š ====
{tool_responses["parking"]}
"""    
    prompt += """
è«‹å°‡ä»¥ä¸Šè³‡è¨Šæ•´åˆæˆä¸€å€‹é€£è²«çš„å›æ‡‰ï¼Œé¿å…é‡è¤‡è³‡è¨Šï¼Œä¸¦æ ¹æ“šå•é¡Œçš„æ ¸å¿ƒéœ€æ±‚é€²è¡Œå„ªå…ˆæ’åºï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
å›æ‡‰æ‡‰è©²:
1. å…ˆå›ç­”ç”¨æˆ¶æœ€é—œå¿ƒçš„å•é¡Œ
2. å°‡ç›¸é—œè³‡è¨Šçµ„ç¹”åœ¨ä¸€èµ·
3. æä¾›ä¸€å€‹ç°¡çŸ­çš„ç¸½çµï¼ŒåŒ…å«æœ€é‡è¦çš„æé†’æˆ–å»ºè­°
4. ä¿æŒå‹å–„ã€å°ˆæ¥­çš„èªæ°£
5. ç›¡é‡æ¡ç”¨åŸæœ¬çš„èªè¨€é¢¨æ ¼ï¼Œè®“ç”¨æˆ¶æ„Ÿåˆ°è¦ªåˆ‡

è«‹æä¾›æ•´åˆå¾Œçš„å®Œæ•´å›æ‡‰:"""
    
    return prompt

# å‰µå»º LangGraph å·¥ä½œæµ
def create_travel_assistant_workflow():
    """å‰µå»ºæ—…éŠåŠ©æ‰‹å·¥ä½œæµ"""
    # åˆå§‹åŒ– StateGraph
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ ç¯€é»
    workflow.add_node("decide", decide_tools)
    workflow.add_node("highway", call_highway_tool)
    workflow.add_node("route", call_route_tool)
    workflow.add_node("weather", call_weather_tool)
    workflow.add_node("parking", call_parking_tool)
    workflow.add_node("general", call_general_tool)
    workflow.add_node("synthesize", synthesize_results)
    
    # è¨­ç½®å…¥å£é»
    workflow.set_entry_point("decide")
    
    # æ·»åŠ æ¢ä»¶é‚Šï¼Œå¾ decide åˆ°å…¶ä»–ç¯€é»
    workflow.add_conditional_edges("decide", route_to_tools)
    
    # æ‰€æœ‰å·¥å…·ç¯€é»æŒ‡å‘ synthesize ç¯€é»
    workflow.add_edge("highway", "synthesize")
    workflow.add_edge("route", "synthesize")
    workflow.add_edge("weather", "synthesize")
    workflow.add_edge("parking", "synthesize")
    workflow.add_edge("general", "synthesize")
    workflow.add_edge("synthesize", END)
    
    # ç·¨è­¯å·¥ä½œæµ
    return workflow.compile()

# å‰µå»ºæ—…éŠåŠ©æ‰‹é¡
class TravelAssistant:
    """æ—…éŠåŠ©æ‰‹é¡ï¼Œå°è£ LangGraph å·¥ä½œæµ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ—…éŠåŠ©æ‰‹"""
        self.graph = create_travel_assistant_workflow()
    
    def process_query(self, query: str) -> str:
        """
        è™•ç†ç”¨æˆ¶æŸ¥è©¢
        
        åƒæ•¸:
            query (str): ç”¨æˆ¶æŸ¥è©¢
            
        è¿”å›:
            str: å›æ‡‰
        """
        # åˆå§‹åŒ–ç‹€æ…‹
        initial_state = {
            "messages": [{"role": "user", "content": query}],
            "query": query,
            "tools_to_use": [],
            "tool_results": {},
            "final_response": None
        }
        
        # åŸ·è¡Œå·¥ä½œæµ
        final_state = self.graph.invoke(initial_state)
        
        # è¿”å›æœ€çµ‚å›æ‡‰
        return final_state["final_response"]
        
    def stream_process(self, query: str):
        """
        æµå¼è™•ç†ç”¨æˆ¶æŸ¥è©¢ï¼Œå¯ä»¥çœ‹åˆ°æ¯å€‹æ­¥é©Ÿçš„åŸ·è¡Œçµæœ
        
        åƒæ•¸:
            query (str): ç”¨æˆ¶æŸ¥è©¢
            
        è¿”å›:
            generator: æ¯å€‹æ­¥é©Ÿçš„åŸ·è¡Œçµæœ
        """
        # åˆå§‹åŒ–ç‹€æ…‹
        initial_state = {
            "messages": [{"role": "user", "content": query}],
            "query": query,
            "tools_to_use": [],
            "tool_results": {},
            "final_response": None
        }
        
        # æµå¼åŸ·è¡Œå·¥ä½œæµ
        for state in self.graph.stream(initial_state):
            yield state


# å¦‚æœç›´æ¥é‹è¡Œæ­¤æª”æ¡ˆï¼Œå‰‡ä½œç‚ºç¤ºç¯„
if __name__ == "__main__":
    # åˆå§‹åŒ–æ—…éŠåŠ©æ‰‹
    import time
    assistant = TravelAssistant()
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        #"æˆ‘æƒ³å¾å°åŒ—åˆ°å®œè˜­ï¼Œåœ‹é“äº”è™Ÿçš„è·¯æ³å¦‚ä½•ï¼Ÿè«‹ä¹Ÿé †ä¾¿å‘Šè¨´æˆ‘å®œè˜­æ˜å¤©çš„å¤©æ°£ã€‚",
        #"å¾å°ä¸­åˆ°æ—¥æœˆæ½­çš„è·¯ç·šï¼Œé€”ä¸­æœƒç¶“éå“ªäº›æ™¯é»ï¼Ÿé€±æœ«é‚£é‚Šçš„å¤©æ°£å¦‚ä½•ï¼Ÿ",
        "å°åŒ—è»Šç«™é™„è¿‘å“ªè£¡å¯ä»¥åœè»Š",
        "æˆ‘æƒ³å»çˆ¬å±±æˆ‘è¦æ³¨æ„äº›ä»€éº¼äº‹æƒ…?"
    ]
    
    # æ¸¬è©¦å–®ä¸€æŸ¥è©¢
    # query = "æˆ‘æƒ³å¾å°åŒ—åˆ°å®œè˜­ï¼Œåœ‹é“äº”è™Ÿçš„è·¯æ³å¦‚ä½•ï¼Ÿè«‹ä¹Ÿé †ä¾¿å‘Šè¨´æˆ‘å®œè˜­æ˜å¤©çš„å¤©æ°£ã€‚"
    # print(f"\næ¸¬è©¦æŸ¥è©¢: {query}")
    
    # ä½¿ç”¨æµå¼è™•ç†ä¾†æŸ¥çœ‹æ¯å€‹æ­¥é©Ÿ
    # print("\n=== æµå¼è™•ç† ===")
    # for state in assistant.stream_process(query):
    #     # æ‰“å°ç•¶å‰ç‹€æ…‹
    #     if "tools_to_use" in state and state["tools_to_use"]:
    #         print(f"é¸æ“‡ä½¿ç”¨çš„å·¥å…·: {state['tools_to_use']}")
    #     if "tool_results" in state and state["tool_results"]:
    #         tools_done = list(state["tool_results"].keys())
    #         if tools_done:
    #             print(f"å®Œæˆçš„å·¥å…·: {tools_done}")
    #     if "final_response" in state and state["final_response"]:
    #         print("\næœ€çµ‚å›æ‡‰:")
    #         print(state["final_response"])
    
    # æ¸¬è©¦æ‰€æœ‰æŸ¥è©¢
    print("\n\n=== æ¸¬è©¦æ‰€æœ‰æŸ¥è©¢ ===")
    for query in test_queries:
        start_time = time.time()
        print(f"\næ¸¬è©¦æŸ¥è©¢: {query}")
        result = assistant.process_query(query)
        print("å›æ‡‰:", result)
        elapsed_time = time.time() - start_time
        print(f"å›æ‡‰ (è€—æ™‚ {elapsed_time:.2f}ç§’):")
        print("="*80)